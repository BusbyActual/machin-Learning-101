### Training models

y Housing price
x Square footage

y = w1x1 + b


y = predicted label / desired output
b = bias
1 is dimension
w is weight of feature
x is a feature

l2 loss or squared error

// we want to minimize loss! by a process called empirical risk minimization

Loss is the penalty for a bad prediction - inicates how bad a prediction it was
We want loss as low as possible accross our metrics.

Mean square error is the average squared loss per example

x is features
y is labes
predictions(x) is a function that predicts with bias via weights
d is data set
n is number of examples in D

Although MSE is commonly-used in machine learning, it is neither the only practical loss function nor the best loss function for all circumstances.